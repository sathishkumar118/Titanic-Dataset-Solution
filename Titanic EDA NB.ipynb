{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import necessary libraries"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n# Loading the data in pandas dataframe\ngender_submission = pd.read_csv(\"../input/titanic/gender_submission.csv\")\ntest = pd.read_csv(\"../input/titanic/test.csv\")\ntrain = pd.read_csv(\"../input/titanic/train.csv\")\nprint(train.info())\nprint(train.head())","execution_count":1,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nNone\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Dropping unwanted columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Title'] = train.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n#assign a value for missing titles\ntrain['Title'] = train['Title'].fillna('NoTitle')\n#Unify titles\ntrain['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')\n\ntest['Title'] = test.Name.str.extract('([A-Za-z]+)\\.', expand=False)\n#assign a value for missing titles\ntest['Title'] = test['Title'].fillna('NoTitle')\n#Unify titles\ntest['Title'] = test['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')\n\nX_train = train.drop(columns = ['Survived','Ticket','Name','Cabin'])\nX_test = test.drop(columns = ['Ticket','Name','Cabin'])\nX_train=X_train.set_index('PassengerId')\nX_test=X_test.set_index('PassengerId')\ny_train = train.Survived\ny_test = gender_submission.Survived\nX_train.info()","execution_count":2,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 8 columns):\nPclass      891 non-null int64\nSex         891 non-null object\nAge         714 non-null float64\nSibSp       891 non-null int64\nParch       891 non-null int64\nFare        891 non-null float64\nEmbarked    889 non-null object\nTitle       891 non-null object\ndtypes: float64(2), int64(3), object(3)\nmemory usage: 62.6+ KB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Filling the missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.info())\n# fill missing values\nX_train.Age=X_train.Age.fillna(X_train.Age.median())\n#create bands for age\nX_train.loc[ X_train['Age'] <= 16, 'Age'] = 0\nX_train.loc[ (X_train['Age'] > 16) & (X_train['Age'] <= 32), 'Age'] = 1\nX_train.loc[ (X_train['Age'] > 32) & (X_train['Age'] <= 48), 'Age'] = 2\nX_train.loc[ (X_train['Age'] > 48) & (X_train['Age'] <= 64), 'Age'] = 3\nX_train.loc[ X_train['Age'] > 64, 'Age'] = 4\nX_train['Age'] = X_train['Age'].astype(int)\n\nX_test.Age=X_test.Age.fillna(X_test.Age.median())\nX_test.loc[ X_test['Age'] <= 16, 'Age'] = 0\nX_test.loc[ (X_test['Age'] > 16) & (X_test['Age'] <= 32), 'Age'] = 1\nX_test.loc[ (X_test['Age'] > 32) & (X_test['Age'] <= 48), 'Age'] = 2\nX_test.loc[ (X_test['Age'] > 48) & (X_test['Age'] <= 64), 'Age'] = 3\nX_test.loc[ X_test['Age'] > 64, 'Age'] = 4\nX_test['Age'] = X_test['Age'].astype(int)\n\nX_train.Fare=X_train.Fare.fillna(X_train.Age.median())\n#create bands for fare\nX_train.loc[ X_train['Fare'] <= 7.91, 'Fare'] = 0\nX_train.loc[ (X_train['Fare'] > 7.91) & (X_train['Fare'] <= 14.454), 'Fare'] = 1\nX_train.loc[ (X_train['Fare'] > 14.454) & (X_train['Fare'] <= 31), 'Fare'] = 2\nX_train.loc[ X_train['Fare'] > 31, 'Fare'] = 3\nX_train.Fare = X_train.Fare.astype(int)\n\nX_test.Fare=X_test.Fare.fillna(X_test.Age.median())\n#create bands for fare\nX_test.loc[ X_test['Fare'] <= 7.91, 'Fare'] = 0\nX_test.loc[ (X_test['Fare'] > 7.91) & (X_test['Fare'] <= 14.454), 'Fare'] = 1\nX_test.loc[ (X_test['Fare'] > 14.454) & (X_test['Fare'] <= 31), 'Fare'] = 2\nX_test.loc[ X_test['Fare'] > 31, 'Fare'] = 3\nX_test['Fare'] = X_test['Fare'].astype(int)\nX_test.Fare = X_test.Fare.astype(int)\nprint(X_train.info())","execution_count":3,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 8 columns):\nPclass      891 non-null int64\nSex         891 non-null object\nAge         714 non-null float64\nSibSp       891 non-null int64\nParch       891 non-null int64\nFare        891 non-null float64\nEmbarked    889 non-null object\nTitle       891 non-null object\ndtypes: float64(2), int64(3), object(3)\nmemory usage: 62.6+ KB\nNone\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 891 entries, 1 to 891\nData columns (total 8 columns):\nPclass      891 non-null int64\nSex         891 non-null object\nAge         891 non-null int64\nSibSp       891 non-null int64\nParch       891 non-null int64\nFare        891 non-null int64\nEmbarked    889 non-null object\nTitle       891 non-null object\ndtypes: int64(5), object(3)\nmemory usage: 62.6+ KB\nNone\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Filter categorical columns using mask and turn it into a list"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_feature_mask = X_train.dtypes==object\ncategorical_cols = X_train.columns[categorical_feature_mask].tolist()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generate LastName column from Name by using the separator ','"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['LastName'] = train.Name.apply(lambda x:x.split(sep=',')[0])\ntrain.info()","execution_count":5,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 14 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\nTitle          891 non-null object\nLastName       891 non-null object\ndtypes: float64(2), int64(5), object(7)\nmemory usage: 97.6+ KB\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Import labelencoder to encode categorical values"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n# instantiate labelencoder object\nle = LabelEncoder()\nX_train.Sex = le.fit_transform(X_train.Sex)\nX_test.Sex = le.fit_transform(X_test.Sex)\nX_train.Embarked = X_train.Embarked.fillna(X_train['Embarked'].value_counts().idxmax())\nX_train.Embarked = le.fit_transform(X_train.Embarked)\nX_test.Embarked = X_test.Embarked.fillna(X_test['Embarked'].value_counts().idxmax())\nX_test.Embarked = le.fit_transform(X_test.Embarked)\nX_train.Title = X_train.Title.fillna(X_train['Title'].value_counts().idxmax())\nX_train.Title = le.fit_transform(X_train.Title)\nX_test.Title = X_test.Title.fillna(X_test['Title'].value_counts().idxmax())\nX_test.Title = le.fit_transform(X_test.Title)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Encoding the categorical values with one hot encoder"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer(\n    [('one_hot_encoder', OneHotEncoder(), [0,2,5,6,7])],    # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n    remainder='passthrough'                         # Leave the rest of the columns untouched\n)\nX_ohe_train = np.array(ct.fit_transform(X_train), dtype=np.float)\nX_ohe_test = np.array(ct.fit_transform(X_test), dtype=np.float)","execution_count":7,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"# Feature scaling needs to be done for continuous columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nmin_max=MinMaxScaler(feature_range=(0, 1))\n# To scale data \nX_train_minmax = X_ohe_train\nX_test_minmax = X_ohe_test\nX_train_minmax[:,14:17]=min_max.fit_transform(X_train_minmax[:,14:17])\nX_test_minmax[:,14:17]=min_max.fit_transform(X_test_minmax[:,14:17])","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#percentage of people survived\nprint(\"percentage of people survived :\",round(y_train.sum()/y_train.count(),2)*100)\ngroupby_sex_total = train.groupby('Sex').sum().Survived\ngroupby_sex_survived = train.groupby('Sex').count().Survived\n#percentage of people survived grouped by sex\nprint(\"percentage of people survived grouped by sex : \\n\",str(round(groupby_sex_total/groupby_sex_survived*100,2)))","execution_count":9,"outputs":[{"output_type":"stream","text":"percentage of people survived : 38.0\npercentage of people survived grouped by sex : \n Sex\nfemale    74.20\nmale      18.89\nName: Survived, dtype: float64\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nlr = LinearRegression()\n#X_train = MinMaxScaler().fit_transform(X_train)\nlr.fit(X_train_minmax,y_train)\ny_pred = lr.predict(X_test_minmax)\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",lr.score(X_test_minmax, y_test))","execution_count":10,"outputs":[{"output_type":"stream","text":"Accuracy: 0.6331357059622169\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train_minmax,y_train)\n\ny_pred=clf.predict(X_test_minmax)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Find accuracy of each model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import roc_auc_score\n# Model Accuracy, how often is the classifier correct?\nAccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\",Accuracy)\nroc_score = roc_auc_score(y_test, y_pred)\nprint(\"ROC_AUC_SCORE : \",roc_score)\nCM = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix : \\n\",CM)\nreport = classification_report(y_test, y_pred)\nprint(\"Classification Report :\\n\",report)","execution_count":12,"outputs":[{"output_type":"stream","text":"Accuracy: 0.8301435406698564\nROC_AUC_SCORE :  0.8214285714285715\nConfusion Matrix : \n [[227  39]\n [ 32 120]]\nClassification Report :\n               precision    recall  f1-score   support\n\n           0       0.88      0.85      0.86       266\n           1       0.75      0.79      0.77       152\n\n    accuracy                           0.83       418\n   macro avg       0.82      0.82      0.82       418\nweighted avg       0.83      0.83      0.83       418\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Neural Network using tensorflow","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dependencies\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# Neural network\nmodel = Sequential()\nmodel.add(Dense(20, activation='relu',input_shape=(X_train_minmax.shape[1],)))\nmodel.add(Dense(20, activation='softmax'))\nmodel.add(Dense(16, activation='softmax'))\nmodel.add(Dense(2, activation='softmax'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n#compiling the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy',metrics=['acc'])\n\nfrom keras.callbacks import EarlyStopping\n#set early stopping monitor so the model stops training when it won't improve anymore\nearly_stopping_monitor = EarlyStopping(patience=3)\n\n#train model\nmodel.fit(X_train_minmax, y_train, validation_split=0.3, epochs=50, callbacks=[early_stopping_monitor])","execution_count":14,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Train on 623 samples, validate on 268 samples\nEpoch 1/50\n623/623 [==============================] - 1s 1ms/step - loss: 0.8878 - acc: 0.3949 - val_loss: 0.9096 - val_acc: 0.3582\nEpoch 2/50\n623/623 [==============================] - 0s 99us/step - loss: 0.8694 - acc: 0.3949 - val_loss: 0.8892 - val_acc: 0.3582\nEpoch 3/50\n623/623 [==============================] - 0s 85us/step - loss: 0.8516 - acc: 0.3949 - val_loss: 0.8700 - val_acc: 0.3582\nEpoch 4/50\n623/623 [==============================] - 0s 82us/step - loss: 0.8349 - acc: 0.3949 - val_loss: 0.8517 - val_acc: 0.3582\nEpoch 5/50\n623/623 [==============================] - 0s 86us/step - loss: 0.8192 - acc: 0.3949 - val_loss: 0.8351 - val_acc: 0.3582\nEpoch 6/50\n623/623 [==============================] - 0s 91us/step - loss: 0.8049 - acc: 0.3949 - val_loss: 0.8191 - val_acc: 0.3582\nEpoch 7/50\n623/623 [==============================] - 0s 81us/step - loss: 0.7916 - acc: 0.3949 - val_loss: 0.8051 - val_acc: 0.3582\nEpoch 8/50\n623/623 [==============================] - 0s 92us/step - loss: 0.7802 - acc: 0.3949 - val_loss: 0.7913 - val_acc: 0.3582\nEpoch 9/50\n623/623 [==============================] - 0s 88us/step - loss: 0.7688 - acc: 0.3949 - val_loss: 0.7800 - val_acc: 0.3582\nEpoch 10/50\n623/623 [==============================] - 0s 90us/step - loss: 0.7590 - acc: 0.3949 - val_loss: 0.7690 - val_acc: 0.3582\nEpoch 11/50\n623/623 [==============================] - 0s 94us/step - loss: 0.7500 - acc: 0.3949 - val_loss: 0.7585 - val_acc: 0.3582\nEpoch 12/50\n623/623 [==============================] - 0s 92us/step - loss: 0.7413 - acc: 0.3949 - val_loss: 0.7490 - val_acc: 0.3582\nEpoch 13/50\n623/623 [==============================] - 0s 96us/step - loss: 0.7334 - acc: 0.3949 - val_loss: 0.7399 - val_acc: 0.3582\nEpoch 14/50\n623/623 [==============================] - 0s 87us/step - loss: 0.7258 - acc: 0.3949 - val_loss: 0.7315 - val_acc: 0.3582\nEpoch 15/50\n623/623 [==============================] - 0s 82us/step - loss: 0.7189 - acc: 0.3949 - val_loss: 0.7236 - val_acc: 0.3582\nEpoch 16/50\n623/623 [==============================] - 0s 83us/step - loss: 0.7125 - acc: 0.3949 - val_loss: 0.7161 - val_acc: 0.3582\nEpoch 17/50\n623/623 [==============================] - 0s 85us/step - loss: 0.7064 - acc: 0.3949 - val_loss: 0.7090 - val_acc: 0.3582\nEpoch 18/50\n623/623 [==============================] - 0s 82us/step - loss: 0.7006 - acc: 0.3949 - val_loss: 0.7027 - val_acc: 0.3582\nEpoch 19/50\n623/623 [==============================] - 0s 92us/step - loss: 0.6950 - acc: 0.3949 - val_loss: 0.6966 - val_acc: 0.3582\nEpoch 20/50\n623/623 [==============================] - 0s 89us/step - loss: 0.6899 - acc: 0.3949 - val_loss: 0.6907 - val_acc: 0.3582\nEpoch 21/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6851 - acc: 0.3949 - val_loss: 0.6849 - val_acc: 0.3582\nEpoch 22/50\n623/623 [==============================] - 0s 82us/step - loss: 0.6804 - acc: 0.6790 - val_loss: 0.6802 - val_acc: 0.8022\nEpoch 23/50\n623/623 [==============================] - 0s 89us/step - loss: 0.6761 - acc: 0.8250 - val_loss: 0.6748 - val_acc: 0.8172\nEpoch 24/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6719 - acc: 0.8266 - val_loss: 0.6704 - val_acc: 0.8209\nEpoch 25/50\n623/623 [==============================] - 0s 84us/step - loss: 0.6679 - acc: 0.8283 - val_loss: 0.6655 - val_acc: 0.8172\nEpoch 26/50\n623/623 [==============================] - 0s 83us/step - loss: 0.6639 - acc: 0.8266 - val_loss: 0.6612 - val_acc: 0.8246\nEpoch 27/50\n623/623 [==============================] - 0s 93us/step - loss: 0.6599 - acc: 0.8299 - val_loss: 0.6566 - val_acc: 0.8209\nEpoch 28/50\n623/623 [==============================] - 0s 101us/step - loss: 0.6558 - acc: 0.8283 - val_loss: 0.6521 - val_acc: 0.8246\nEpoch 29/50\n623/623 [==============================] - 0s 109us/step - loss: 0.6518 - acc: 0.8283 - val_loss: 0.6474 - val_acc: 0.8209\nEpoch 30/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6474 - acc: 0.8299 - val_loss: 0.6425 - val_acc: 0.8246\nEpoch 31/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6430 - acc: 0.8283 - val_loss: 0.6375 - val_acc: 0.8246\nEpoch 32/50\n623/623 [==============================] - 0s 88us/step - loss: 0.6383 - acc: 0.8315 - val_loss: 0.6324 - val_acc: 0.8246\nEpoch 33/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6333 - acc: 0.8331 - val_loss: 0.6271 - val_acc: 0.8321\nEpoch 34/50\n623/623 [==============================] - 0s 87us/step - loss: 0.6283 - acc: 0.8363 - val_loss: 0.6216 - val_acc: 0.8396\nEpoch 35/50\n623/623 [==============================] - 0s 98us/step - loss: 0.6232 - acc: 0.8395 - val_loss: 0.6160 - val_acc: 0.8470\nEpoch 36/50\n623/623 [==============================] - 0s 86us/step - loss: 0.6176 - acc: 0.8395 - val_loss: 0.6103 - val_acc: 0.8507\nEpoch 37/50\n623/623 [==============================] - 0s 106us/step - loss: 0.6122 - acc: 0.8395 - val_loss: 0.6045 - val_acc: 0.8470\nEpoch 38/50\n623/623 [==============================] - 0s 84us/step - loss: 0.6063 - acc: 0.8411 - val_loss: 0.5984 - val_acc: 0.8470\nEpoch 39/50\n623/623 [==============================] - 0s 81us/step - loss: 0.6003 - acc: 0.8427 - val_loss: 0.5925 - val_acc: 0.8507\nEpoch 40/50\n623/623 [==============================] - 0s 91us/step - loss: 0.5944 - acc: 0.8443 - val_loss: 0.5868 - val_acc: 0.8433\nEpoch 41/50\n623/623 [==============================] - 0s 89us/step - loss: 0.5886 - acc: 0.8427 - val_loss: 0.5809 - val_acc: 0.8433\nEpoch 42/50\n623/623 [==============================] - 0s 87us/step - loss: 0.5827 - acc: 0.8475 - val_loss: 0.5746 - val_acc: 0.8507\nEpoch 43/50\n623/623 [==============================] - 0s 90us/step - loss: 0.5767 - acc: 0.8443 - val_loss: 0.5689 - val_acc: 0.8507\nEpoch 44/50\n623/623 [==============================] - 0s 93us/step - loss: 0.5706 - acc: 0.8475 - val_loss: 0.5631 - val_acc: 0.8433\nEpoch 45/50\n623/623 [==============================] - 0s 89us/step - loss: 0.5648 - acc: 0.8459 - val_loss: 0.5573 - val_acc: 0.8433\nEpoch 46/50\n623/623 [==============================] - 0s 84us/step - loss: 0.5591 - acc: 0.8491 - val_loss: 0.5517 - val_acc: 0.8433\nEpoch 47/50\n623/623 [==============================] - 0s 88us/step - loss: 0.5535 - acc: 0.8475 - val_loss: 0.5463 - val_acc: 0.8433\nEpoch 48/50\n623/623 [==============================] - 0s 91us/step - loss: 0.5480 - acc: 0.8491 - val_loss: 0.5413 - val_acc: 0.8433\nEpoch 49/50\n623/623 [==============================] - 0s 84us/step - loss: 0.5427 - acc: 0.8491 - val_loss: 0.5363 - val_acc: 0.8470\nEpoch 50/50\n623/623 [==============================] - 0s 90us/step - loss: 0.5376 - acc: 0.8475 - val_loss: 0.5314 - val_acc: 0.8433\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fda5c200dd8>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = (model.predict(X_test_minmax)>=0.5).astype('int64')\naccuracy = model.evaluate(X_test_minmax,y_test,verbose = 0)[1]\nprint(\"Accuracy score of the neural network is :\",accuracy)","execution_count":15,"outputs":[{"output_type":"stream","text":"Accuracy score of the neural network is : 0.9090909361839294\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import roc_auc_score\n# Model Accuracy, how often is the classifier correct?\nAccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\",Accuracy)\nroc_score = roc_auc_score(y_test, y_pred)\nprint(\"ROC_AUC_SCORE : \",roc_score)\nCM = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix : \\n\",CM)\nreport = classification_report(y_test, y_pred,output_dict=True)\nprint(\"Classification Report :\\n\",report)","execution_count":16,"outputs":[{"output_type":"stream","text":"Accuracy: 0.9090909090909091\nROC_AUC_SCORE :  0.8961466165413535\nConfusion Matrix : \n [[251  15]\n [ 23 129]]\nClassification Report :\n {'0': {'precision': 0.916058394160584, 'recall': 0.943609022556391, 'f1-score': 0.9296296296296296, 'support': 266}, '1': {'precision': 0.8958333333333334, 'recall': 0.8486842105263158, 'f1-score': 0.8716216216216217, 'support': 152}, 'accuracy': 0.9090909090909091, 'macro avg': {'precision': 0.9059458637469586, 'recall': 0.8961466165413534, 'f1-score': 0.9006256256256256, 'support': 418}, 'weighted avg': {'precision': 0.9087038265870384, 'recall': 0.9090909090909091, 'f1-score': 0.9085358085358086, 'support': 418}}\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Generating the final results and saving it in a CSV file"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_results = pd.DataFrame(y_pred, columns = ['Survived'])\nfinal_results['PassengerId'] = gender_submission.PassengerId\nfinal_results=final_results.set_index('PassengerId')\nfinal_results.to_csv('FinalResults-'+str(round(accuracy,2))+str(CM)'.csv')","execution_count":17,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-17-639c3ec36170>, line 4)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-639c3ec36170>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    final_results.to_csv('FinalResults-'+str(round(accuracy,2))+str(CM)'.csv')\u001b[0m\n\u001b[0m                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}